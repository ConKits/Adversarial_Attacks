{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c576b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae18c91-6fff-4a16-a189-f74119751f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CKPT_PATH = \"./resnet101_gtsrb_best.pt\"\n",
    "NUM_CLASSES = 43\n",
    "DATA_ROOT = \"./data_gtsrb\"\n",
    "IMG_SIZE = 224\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "SUBSET_SIZE = 120   # small & stable\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "#STOP_CLASS = 14\n",
    "TARGET = 9\n",
    "PATCH_SIZE = 60\n",
    "EPOCHS = 20\n",
    "LR = 0.03\n",
    "\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579e616-1faa-4311-9716-ba1945af2a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "weights = models.ResNet101_Weights.IMAGENET1K_V2\n",
    "model = models.resnet101(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "\n",
    "# Robust: checkpoint might be {\"model_state\": ...} or directly a state_dict\n",
    "state_dict = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b29c09-dedf-42ac-8c26-715182955435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class UniversalTargetedPatchTrainer:\n",
    "#     def __init__(self, model, target_class, patch_size, lr):\n",
    "#         self.model = model\n",
    "#         self.target_class = target_class\n",
    "#         self.patch_size = patch_size\n",
    "#         self.device = DEVICE\n",
    "\n",
    "#         self.patch = torch.rand(\n",
    "#             3, patch_size, patch_size,\n",
    "#             device=self.device,\n",
    "#             requires_grad=True\n",
    "#         )\n",
    "\n",
    "#         self.optimizer = optim.Adam([self.patch], lr=lr)\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def apply_patch(self, images,random_pos=True):\n",
    "#         B, C, H, W = images.shape\n",
    "#         patched = images.clone()\n",
    "\n",
    "#         for i in range(B):\n",
    "#             if random_pos:\n",
    "#                 x = random.randint(0, W - self.patch_size)\n",
    "#                 y = random.randint(0, H - self.patch_size)\n",
    "#             else:\n",
    "#                 x = (W - self.patch_size) // 2\n",
    "#                 y = (H - self.patch_size) // 2\n",
    "\n",
    "#             patched[i, :, y:y+self.patch_size, x:x+self.patch_size] = self.patch\n",
    "\n",
    "        \n",
    "#         return patched.clamp(-2.5, 2.5)\n",
    "\n",
    "#     def train_on_batch(self, images):\n",
    "#         images = images.to(self.device)\n",
    "\n",
    "#         patched = self.apply_patch(images)\n",
    "#         outputs = self.model(patched)\n",
    "\n",
    "#         targets = torch.full(\n",
    "#             (images.size(0),),\n",
    "#             self.target_class,\n",
    "#             device=self.device,\n",
    "#             dtype=torch.long\n",
    "#         )\n",
    "\n",
    "#         loss = self.criterion(outputs, targets)\n",
    "\n",
    "#         self.optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "\n",
    "#         self.patch.data.clamp_(-2.5, 2.5)\n",
    "#         return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf69b6-2ba6-498a-9fa4-854046f0754b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UniversalTargetedPatchTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        target_class,\n",
    "        patch_size,\n",
    "        lr,\n",
    "        init_patch=None,\n",
    "        clamp_min=-2.5,\n",
    "        clamp_max=2.5\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.target_class = target_class\n",
    "        self.patch_size = patch_size\n",
    "        self.device = DEVICE\n",
    "        self.clamp_min = clamp_min\n",
    "        self.clamp_max = clamp_max\n",
    "\n",
    "        # ---- PATCH INITIALIZATION ----\n",
    "        if init_patch is not None:\n",
    "            assert init_patch.shape == (3, patch_size, patch_size), \\\n",
    "                f\"Expected patch shape (3,{patch_size},{patch_size})\"\n",
    "\n",
    "            self.patch = init_patch.to(self.device).clone()\n",
    "            self.patch.requires_grad_(True)\n",
    "            print(\"Loaded existing patch – continuing optimization\")\n",
    "\n",
    "        else:\n",
    "            self.patch = torch.rand(\n",
    "                3, patch_size, patch_size,\n",
    "                device=self.device,\n",
    "                requires_grad=True\n",
    "            )\n",
    "            print(\"Initialized new random patch\")\n",
    "\n",
    "        # ---- OPTIMIZER ----\n",
    "        self.optimizer = optim.Adam([self.patch], lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def apply_patch(self, images, random_pos=True):\n",
    "        B, C, H, W = images.shape\n",
    "        patched = images.clone()\n",
    "\n",
    "        for i in range(B):\n",
    "            if random_pos:\n",
    "                x = random.randint(0, W - self.patch_size)\n",
    "                y = random.randint(0, H - self.patch_size)\n",
    "            else:\n",
    "                x = (W - self.patch_size) // 2\n",
    "                y = (H - self.patch_size) // 2\n",
    "\n",
    "            patched[i, :, y:y+self.patch_size, x:x+self.patch_size] = self.patch\n",
    "\n",
    "        return patched.clamp(self.clamp_min, self.clamp_max)\n",
    "\n",
    "    def train_on_batch(self, images):\n",
    "        images = images.to(self.device)\n",
    "\n",
    "        patched = self.apply_patch(images)\n",
    "        outputs = self.model(patched)\n",
    "\n",
    "        targets = torch.full(\n",
    "            (images.size(0),),\n",
    "            self.target_class,\n",
    "            device=self.device,\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # keep patch bounded\n",
    "        self.patch.data.clamp_(self.clamp_min, self.clamp_max)\n",
    "\n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647bb49-e51b-47b3-aea9-229e9f5ff807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_target_class(dataset, target_class):\n",
    "    indices = [i for i, (_, y) in enumerate(dataset) if y != target_class]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "SUBSET_SIZE = 300   # small & stable\n",
    "\n",
    "imagenet_mean = (0.485, 0.1, 0.106)\n",
    "imagenet_std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "test_set = datasets.GTSRB(\n",
    "    root=DATA_ROOT,\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=tfms\n",
    ")\n",
    "\n",
    "indices = random.sample(range(len(test_set)), SUBSET_SIZE)\n",
    "patch_test_set = Subset(test_set, indices)\n",
    "#print(len(indices))\n",
    "patch_train_set = remove_target_class(patch_test_set, TARGET)\n",
    "print(len(patch_train_set))\n",
    "Patch_loader = DataLoader(\n",
    "    patch_train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "indices = random.sample(range(len(test_set)), 6000)\n",
    "small_test_set = Subset(test_set, indices)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    small_test_set,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b229a-5786-423d-8ca2-06d4242fc27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick a real STOP image\n",
    "for images, labels in test_loader:\n",
    "    idx = (labels == TARGET).nonzero(as_tuple=True)[0]\n",
    "    if len(idx) > 0:\n",
    "        img = images[idx[0]:idx[0]+1].to(DEVICE)\n",
    "        img_v=images[idx[0]]\n",
    "        lbl=labels[idx[0]]\n",
    "        break\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Target Sign\",lbl.item(),\":\", \"Prediction:\",model(img).argmax(1).item())\n",
    "\n",
    "\n",
    "\n",
    "img_v = img_v.detach().cpu()\n",
    "img = img_v.permute(1,2,0).clamp(0,1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939fee7-20ac-483b-a97e-2b0487d860cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from attacks.adv_patch_trainer import UniversalTargetedPatchTrainer\n",
    "PATCH_SIZE = 40\n",
    "EPOCHS = 50\n",
    "LR = 0.002\n",
    "BATCH_LIMIT=150\n",
    "\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "trainer = UniversalTargetedPatchTrainer(\n",
    "    model=model,\n",
    "    target_class=TARGET,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    lr=LR,\n",
    "    init_patch=torch.load(f\"./Patches/Target_{TARGET}_patch.pt\")\n",
    ")\n",
    "\n",
    "#for epoch in range(EPOCHS):\n",
    "epoch=0\n",
    "while epoch<100:\n",
    "    total_loss = 0\n",
    "    batches = 0\n",
    "\n",
    "    for  i, (images, _) in enumerate (Patch_loader):\n",
    "        images = images[:4]  # very important for GPU stability\n",
    "        loss = trainer.train_on_batch(images)\n",
    "        total_loss += loss\n",
    "        batches += 1\n",
    "        if i >= BATCH_LIMIT:\n",
    "            break\n",
    "    avg_loss=total_loss / batches\n",
    "    print(f\"Epoch {epoch+1}: avg loss = {avg_loss:.4f}\")\n",
    "    if avg_loss<0.15:\n",
    "        break\n",
    "    epoch+=1\n",
    "    \n",
    "torch.save(trainer.patch.detach().cpu(), f\"./Patches/Target_{TARGET}_patch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204af2b-c311-4f76-bb4d-b9fc49bd7c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def targeted_attack_success_rate(model, loader, trainer, target_class):\n",
    "    model.eval()\n",
    "    success = 0\n",
    "    wrong = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        \n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # Exclude the Target images\n",
    "        mask = labels != target_class\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        images = images[mask]\n",
    "        labels = labels[mask]\n",
    "        \n",
    "        patched = trainer.apply_patch(images)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(patched).argmax(dim=1)\n",
    "            \n",
    "        wrong += (preds != labels).sum().item()\n",
    "        success += (preds == target_class).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    return success / total, wrong/total\n",
    "\n",
    "rate,mis_rate = targeted_attack_success_rate(model, test_loader, trainer, TARGET)\n",
    "\n",
    "print(f\"Targeted Attack Success Rate Target {TARGET}: {rate*100:.2f}%\")\n",
    "print(f\"Misclassification Rate: {mis_rate*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b05ac-3933-4b55-981b-29c879afd1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patch = trainer.patch.detach().cpu()\n",
    "\n",
    "# Convert from (C, H, W) → (H, W, C)\n",
    "patch = patch.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(patch)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Adversarial Patch\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac4d8c-b1d3-4fe0-84b9-bcf262e2302d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img.device).view(3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=img.device).view(3,1,1)\n",
    "    return img * std + mean\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images[:4].to(DEVICE)\n",
    "labels = labels[:4]\n",
    "\n",
    "patched = trainer.apply_patch(images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    clean_preds = model(images).argmax(1)\n",
    "    patch_preds = model(patched).argmax(1)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for i in range(4):\n",
    "    # ----- CLEAN IMAGE -----\n",
    "    plt.subplot(2,4,i+1)\n",
    "    clean_img = images[i].detach().cpu()\n",
    "    #clean_img = denormalize(images[i]).detach().cpu()\n",
    "    clean_img = clean_img.permute(1,2,0).clamp(0,1)\n",
    "    plt.imshow(clean_img)\n",
    "    plt.title(f\"Clean\\nPred: {clean_preds[i].item()} | GT: {labels[i].item()}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # ----- PATCHED IMAGE -----\n",
    "    plt.subplot(2,4,i+5)\n",
    "    patched_img = patched[i].detach().cpu()\n",
    "    patched_img = patched_img.permute(1,2,0).clamp(0,1)\n",
    "    plt.imshow(patched_img)\n",
    "    plt.title(f\"Patched\\nPred: {patch_preds[i].item()}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "patch = denormalize(trainer.patch).detach().cpu()\n",
    "\n",
    "# Convert from (C, H, W) → (H, W, C)\n",
    "patch = patch.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(patch)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Adversarial Patch\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10",
   "language": "python",
   "name": "py3.7.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
