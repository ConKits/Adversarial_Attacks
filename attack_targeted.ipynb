{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8c158a-b913-49b3-88e9-f3fb16c90c0f",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Baseline\n",
    "\n",
    "This part aims to answer the following question: Does the model perform well in the absence of attacks?\n",
    "The results obtained here serve as a baseline for future comparisons after the adversarial attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec20c3-fa78-4ba2-9fd8-21c5de49b0e7",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Classes ID and meaning:\n",
    "\n",
    "0- Speed limit (20km/h)\n",
    "\n",
    "1- Speed limit (30km/h)\n",
    "\n",
    "2- Speed limit (50km/h)\n",
    "\n",
    "3- Speed limit (60km/h)\n",
    "\n",
    "4- Speed limit (70km/h)\n",
    "\n",
    "5- Speed limit (80km/h)\n",
    "\n",
    "6- End of speed limit (80km/h)\n",
    "\n",
    "7- Speed limit (100km/h)\n",
    "\n",
    "8- Speed limit (120km/h)\n",
    "\n",
    "9- No passing\n",
    "\n",
    "10- No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "11- Right-of-way at intersection\n",
    "\n",
    "12- Priority road\n",
    "\n",
    "13- Yield\n",
    "\n",
    "14- Stop\n",
    "\n",
    "15- No vehicle\n",
    "\n",
    "16- Vehicles over 3.5 tons prohibited\n",
    "\n",
    "17- No entry\n",
    "\n",
    "18- General caution\n",
    "\n",
    "19- Dangerous curve left\n",
    "\n",
    "20- Dangerous curve right\n",
    "\n",
    "21- Double curve\n",
    "\n",
    "22- Bumpy road\n",
    "\n",
    "23- Slippery road\n",
    "\n",
    "24- Road narrows on the right\n",
    "\n",
    "25- Road work\n",
    "\n",
    "26- Traffic signals\n",
    "\n",
    "27- Pedestrians\n",
    "\n",
    "28- Children crossing\n",
    "\n",
    "29- Bicycles crossing\n",
    "\n",
    "30- Beware of ice/snow\n",
    "\n",
    "31- Wild animals crossing\n",
    "\n",
    "32- End of all speed and passing limits\n",
    "\n",
    "33- Turn right ahead\n",
    "\n",
    "34- Turn left ahead\n",
    "\n",
    "35- Ahead only\n",
    "\n",
    "36- Go straight or right\n",
    "\n",
    "37- Go straight or left\n",
    "\n",
    "38- Keep right\n",
    "\n",
    "39- Keep left\n",
    "\n",
    "40- Roundabout mandatory\n",
    "\n",
    "41- End of no passing\n",
    "\n",
    "42- End no passing vehicles over 3.5 tons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e392f7-2d94-4ccd-96a8-49fce78c4408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "DATA_ROOT = \"./data_gtsrb\"                      \n",
    "CKPT_PATH = \"./checkpoints/resnet101_gtsrb_best.pt\"\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 224                                \n",
    "BATCH_SIZE = 48\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e7bdd-226a-4eda-af1d-47ff81c1ce3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenet_mean = (0.485, 0.456, 0.406)\n",
    "imagenet_std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "test_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "test_set = datasets.GTSRB(root=DATA_ROOT, split=\"test\", download=False, transform=test_tfms)\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Test size:\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a0742-ad25-4391-9d27-e0990272511a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rebuild same architecture\n",
    "weights = models.ResNet101_Weights.IMAGENET1K_V2\n",
    "model = models.resnet101(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device)\n",
    "\n",
    "# Robust: checkpoint might be {\"model_state\": ...} or directly a state_dict\n",
    "state_dict = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device).eval()\n",
    "print(\"Checkpoint loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13a900-0032-44b6-84bc-acef47d57736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confmat = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.long)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        # update confusion matrix\n",
    "        for t, p in zip(y.view(-1), preds.view(-1)):\n",
    "            confmat[t.long(), p.long()] += 1\n",
    "\n",
    "acc = correct / total\n",
    "print(f\"Overall Test Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf53111-b89d-4029-9b94-433be170d235",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Adversarial attacks\n",
    "\n",
    "This part consists of two types of adversarial patch attacks:\n",
    "(A) we overlay the images with a non-optimized sticker to analyze its impact on the model’s performance; and\n",
    "(B) we optimize the sticker in order to further degrade the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bb1f8-14d8-49ce-afc0-138bc6831b18",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Optimized sticker (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8a971-d063-4840-9014-43c5580f3c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Universal targeted patch attack for GTSRB\n",
    "# (paste into your \"Add attack code here\" cell)\n",
    "# ---------------------------\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Subset\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "\n",
    "\n",
    "# 1) Patch application (in *normalized* space)\n",
    "def _normalized_minmax(mean, std, device):\n",
    "    \"\"\"\n",
    "    Given mean/std used for Normalize on [0,1] inputs, compute the min/max\n",
    "    possible values in normalized space when original pixels are in [0,1].\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean, device=device).view(1, 3, 1, 1)\n",
    "    std  = torch.tensor(std, device=device).view(1, 3, 1, 1)\n",
    "    x_min = (0.0 - mean) / std\n",
    "    x_max = (1.0 - mean) / std\n",
    "    return x_min, x_max\n",
    "\n",
    "def apply_noise_patch_batch(\n",
    "    x_norm: torch.Tensor,\n",
    "    patch: torch.Tensor,\n",
    "    patch_size: int = 32,\n",
    "    random_loc: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Overlay a (3,P,P) patch onto a batch of normalized images (N,3,H,W).\n",
    "    Returns patched images (still normalized).\n",
    "\n",
    "    x_norm: (N,3,H,W) already normalized.\n",
    "    patch : (3,P,P) in normalized space.\n",
    "    \"\"\"\n",
    "    assert x_norm.dim() == 4 and x_norm.size(1) == 3\n",
    "    assert patch.dim() == 3 and patch.size(0) == 3\n",
    "    N, C, H, W = x_norm.shape\n",
    "    P = patch_size\n",
    "    assert patch.size(1) == P and patch.size(2) == P\n",
    "    assert P <= H and P <= W\n",
    "\n",
    "    x = x_norm.clone()\n",
    "\n",
    "    if random_loc:\n",
    "        xs = torch.randint(0, H - P + 1, (N,), device=x.device)\n",
    "        ys = torch.randint(0, W - P + 1, (N,), device=x.device)\n",
    "    else:\n",
    "        xs = torch.full((N,), (H - P) // 2, device=x.device, dtype=torch.long)\n",
    "        ys = torch.full((N,), (W - P) // 2, device=x.device, dtype=torch.long)\n",
    "\n",
    "    for i in range(N):\n",
    "        x[i, :, xs[i]:xs[i] + P, ys[i]:ys[i] + P] = patch\n",
    "\n",
    "    # keep values within feasible normalized bounds for [0,1] images\n",
    "    x_min, x_max = _normalized_minmax(imagenet_mean, imagenet_std, x.device)\n",
    "    x = torch.max(torch.min(x, x_max), x_min)\n",
    "    return x\n",
    "\n",
    "def init_patch_from_blurred_target(\n",
    "    train_loader,\n",
    "    device,\n",
    "    target_class: int,\n",
    "    patch_size: int,\n",
    "    imagenet_mean,\n",
    "    imagenet_std,\n",
    "    random_loc_for_crop: bool = False,\n",
    "    blur_kernel: int | None = None,\n",
    "    blur_sigma: float = 2.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Initializes a (3,P,P) patch in *normalized* space by:\n",
    "    - finding one sample of target_class in train_loader\n",
    "    - denormalizing to [0,1]\n",
    "    - taking a P×P crop (center or random)\n",
    "    - applying Gaussian blur\n",
    "    - renormalizing back to ImageNet space\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(imagenet_mean, device=device).view(3, 1, 1)\n",
    "    std  = torch.tensor(imagenet_std,  device=device).view(3, 1, 1)\n",
    "\n",
    "    # Choose a reasonable odd blur kernel if not provided\n",
    "    if blur_kernel is None:\n",
    "        # about P/4, but at least 3, must be odd\n",
    "        k = max(3, patch_size // 4)\n",
    "        blur_kernel = k if (k % 2 == 1) else (k + 1)\n",
    "    else:\n",
    "        if blur_kernel % 2 == 0:\n",
    "            blur_kernel += 1\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        # y is on CPU; x is CPU unless you move it\n",
    "        mask = (y == target_class)\n",
    "        if mask.any():\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            img_norm = x[mask][0]  # (3,H,W), normalized\n",
    "\n",
    "            # denorm to [0,1]\n",
    "            img01 = (img_norm * std + mean).clamp(0, 1)\n",
    "\n",
    "            _, H, W = img01.shape\n",
    "            P = patch_size\n",
    "\n",
    "            if random_loc_for_crop:\n",
    "                top  = torch.randint(0, H - P + 1, (1,), device=device).item()\n",
    "                left = torch.randint(0, W - P + 1, (1,), device=device).item()\n",
    "            else:\n",
    "                top  = (H - P) // 2\n",
    "                left = (W - P) // 2\n",
    "\n",
    "            patch01 = img01[:, top:top+P, left:left+P]  # (3,P,P) in [0,1]\n",
    "\n",
    "            # blur in pixel space\n",
    "            patch01_blur = gaussian_blur(\n",
    "                patch01, kernel_size=[blur_kernel, blur_kernel], sigma=[blur_sigma, blur_sigma]\n",
    "            )\n",
    "\n",
    "            # renorm back to normalized space\n",
    "            patch_norm = (patch01_blur - mean) / std  # (3,P,P)\n",
    "            return patch_norm\n",
    "\n",
    "    # fallback if no target sample found\n",
    "    return None\n",
    "\n",
    "\n",
    "def cw_margin_loss(logits: torch.Tensor, target: torch.Tensor, kappa: float = 0.0):\n",
    "    \"\"\"\n",
    "    Targeted CW-style loss: maximize (z_t - max_{i!=t} z_i).\n",
    "    We *minimize* max(max_other - z_t + kappa, 0).\n",
    "    \"\"\"\n",
    "    # logits: (N, C), target: (N,)\n",
    "    N, C = logits.shape\n",
    "    z_t = logits.gather(1, target.view(-1, 1)).squeeze(1)  # (N,)\n",
    "\n",
    "    # max logit among non-target classes\n",
    "    mask = F.one_hot(target, num_classes=C).bool()\n",
    "    z_other = logits.masked_fill(mask, float(\"-inf\")).max(dim=1).values  # (N,)\n",
    "\n",
    "    # targeted margin objective (hinge)\n",
    "    loss = torch.clamp(z_other - z_t + kappa, min=0.0).mean()\n",
    "    return loss\n",
    "\n",
    "def neg_target_logit_loss(logits: torch.Tensor, target: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Minimize negative target logit => maximize target logit.\n",
    "    \"\"\"\n",
    "    z_t = logits.gather(1, target.view(-1, 1)).squeeze(1)\n",
    "    return (-z_t).mean()\n",
    "\n",
    "def kappa_linear(ep: int, kappa_start=0.0, kappa_end=10.0, ramp_start=5, ramp_end=30):\n",
    "    if ep <= ramp_start:\n",
    "        return kappa_start\n",
    "    if ep >= ramp_end:\n",
    "        return kappa_end\n",
    "    t = (ep - ramp_start) / (ramp_end - ramp_start)\n",
    "    return kappa_start + t * (kappa_end - kappa_start)\n",
    "\n",
    "def optimize_targeted_patch(\n",
    "    model,\n",
    "    train_loader,\n",
    "    device,\n",
    "    target_class: int,\n",
    "    patch_size: int = 32,\n",
    "    epochs: int = 5,\n",
    "    lr: float = 0.05,\n",
    "    random_loc: bool = True,\n",
    "    steps_per_epoch: int | None = None,\n",
    "    tv_weight: float = 0,\n",
    "    init_from_blurred_target: bool = True,\n",
    "    blur_kernel: int | None = None,\n",
    "    blur_sigma: float = 2.0,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    P = patch_size\n",
    "\n",
    "    # Feasible normalized range for [0,1] pixels\n",
    "    x_min, x_max = _normalized_minmax(imagenet_mean, imagenet_std, device)\n",
    "\n",
    "    # --- NEW: initialize patch from blurred target-class crop ---\n",
    "    patch_init = None\n",
    "    if init_from_blurred_target:\n",
    "        patch_init = init_patch_from_blurred_target(\n",
    "            train_loader=train_loader,\n",
    "            device=device,\n",
    "            target_class=target_class,\n",
    "            patch_size=P,\n",
    "            imagenet_mean=imagenet_mean,\n",
    "            imagenet_std=imagenet_std,\n",
    "            random_loc_for_crop=False,   # set True if you want random crop\n",
    "            blur_kernel=blur_kernel,\n",
    "            blur_sigma=blur_sigma,\n",
    "        )\n",
    "\n",
    "    if patch_init is None:\n",
    "        # fallback: small random noise\n",
    "        patch_init = 0.01 * torch.randn(3, P, P, device=device)\n",
    "\n",
    "    patch = patch_init.clone().detach().requires_grad_(True)\n",
    "    opt = torch.optim.Adam([patch], lr=lr)\n",
    "\n",
    "    def total_variation(p):\n",
    "        tv_h = (p[:, 1:, :] - p[:, :-1, :]).abs().mean()\n",
    "        tv_w = (p[:, :, 1:] - p[:, :, :-1]).abs().mean()\n",
    "        return tv_h + tv_w\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        success = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        steps = 0\n",
    "        kappa = kappa_linear(ep, kappa_start=0.0, kappa_end=50.0, ramp_start=1, ramp_end=40)\n",
    "\n",
    "        # Determine how many iterations the bar should run\n",
    "        if steps_per_epoch is None:\n",
    "            total_steps = len(train_loader)\n",
    "        else:\n",
    "            total_steps = min(steps_per_epoch, len(train_loader))\n",
    "\n",
    "        pbar = tqdm(\n",
    "            enumerate(train_loader),\n",
    "            total=total_steps,\n",
    "            desc=f\"Epoch {ep+1}/{epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "\n",
    "        for step, (x, y) in pbar:\n",
    "            if steps_per_epoch is not None and step >= steps_per_epoch:\n",
    "                break\n",
    "\n",
    "            x = x.to(device, non_blocking=True)\n",
    "\n",
    "            x_patched = apply_noise_patch_batch(\n",
    "                x_norm=x,\n",
    "                patch=patch,\n",
    "                patch_size=P,\n",
    "                random_loc=random_loc\n",
    "            )\n",
    "\n",
    "            logits = model(x_patched)\n",
    "            target = torch.full((x.size(0),), target_class, device=device, dtype=torch.long)\n",
    "\n",
    "            # Define different loss types\n",
    "            loss_type = \"cw\"  # \"cw\" | \"logit\" | \"ce\"\n",
    "\n",
    "            if loss_type == \"cw\":\n",
    "                loss = cw_margin_loss(logits, target, kappa=kappa)\n",
    "            elif loss_type == \"logit\":\n",
    "                loss = neg_target_logit_loss(logits, target)\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits, target)\n",
    "            \n",
    "            if tv_weight > 0:\n",
    "                loss = loss + tv_weight * total_variation(patch)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # Clamp patch to feasible normalized range\n",
    "            patch.data = torch.max(torch.min(patch.data, x_max[0]), x_min[0])\n",
    "\n",
    "            # Stats\n",
    "            with torch.no_grad():\n",
    "                preds = logits.argmax(dim=1)\n",
    "                batch_success = (preds == target).sum().item()\n",
    "                success += batch_success\n",
    "                total += target.numel()\n",
    "\n",
    "            steps += 1\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{running_loss/steps:.4f}\",\n",
    "                \"succ%\": f\"{100.0*success/max(total,1):.2f}\",\n",
    "            })\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} | targeted success: {100.0*success/max(total,1):.2f}% | avg loss: {running_loss/max(steps,1):.4f}\")\n",
    "\n",
    "    return patch.detach().cpu()\n",
    "\n",
    "\n",
    "# 3) Build a train loader (GTSRB has a train split)\n",
    "# --- Debug: small subset of train set ---\n",
    "DEBUG_TRAIN_N = 11968  # try 64 / 128 / 256\n",
    "\n",
    "train_set_full = datasets.GTSRB(root=DATA_ROOT, split=\"train\", download=True, transform=test_tfms)\n",
    "\n",
    "rng = np.random.default_rng(0)  # deterministic\n",
    "subset_idx = rng.choice(len(train_set_full), size=min(DEBUG_TRAIN_N, len(train_set_full)), replace=False)\n",
    "\n",
    "train_set = Subset(train_set_full, subset_idx.tolist())\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Train size (debug):\", len(train_set))\n",
    "\n",
    "\n",
    "# 4) Run the attack\n",
    "# Choose a target class (GTSRB labels 0..42).\n",
    "# Common example: 14 = \"Stop\"\n",
    "TARGET_CLASS = 9\n",
    "\n",
    "P = 64  # patch size used later by your notebook\n",
    "patch = optimize_targeted_patch(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    device=device,\n",
    "    target_class=TARGET_CLASS,\n",
    "    patch_size=64,\n",
    "    epochs=50,\n",
    "    lr=0.03,\n",
    "    random_loc=True,\n",
    "    steps_per_epoch=50,\n",
    "    init_from_blurred_target=True,\n",
    "    blur_kernel=3,      # optional\n",
    "    blur_sigma=2.0      # optional\n",
    ")\n",
    "\n",
    "print(\"Patch learned:\", patch.shape, \"target =\", TARGET_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4c9cc-91d9-451b-a614-11c2a0e6f45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"patch\": patch.detach().cpu(),\n",
    "        \"patch_size\": P,\n",
    "        \"imagenet_mean\": imagenet_mean,\n",
    "        \"imagenet_std\": imagenet_std,\n",
    "    },\n",
    "    \"optimized_patch.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b82e48-7cf3-4315-bb9b-d6212aa215cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_accuracy_with_patch(model, loader, device, patch, P=32, random_loc=True):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    patch = patch.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            x_patched = apply_noise_patch_batch(\n",
    "                x_norm=x,\n",
    "                patch_size=P,\n",
    "                patch=patch,\n",
    "                random_loc=random_loc\n",
    "            )\n",
    "\n",
    "            logits = model(x_patched)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.numel()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "patched_acc = eval_accuracy_with_patch(model, test_loader, device, patch, P=64, random_loc=True)\n",
    "print(\"Patched test acc (random loc):\", patched_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8ee79-9d77-43d7-b17f-de51c3c911a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID_TO_NAME = [\n",
    " \"Speed limit (20km/h)\", \"Speed limit (30km/h)\", \"Speed limit (50km/h)\", \"Speed limit (60km/h)\",\n",
    " \"Speed limit (70km/h)\", \"Speed limit (80km/h)\", \"End of speed limit (80km/h)\", \"Speed limit (100km/h)\",\n",
    " \"Speed limit (120km/h)\", \"No passing\", \"No passing for vehicles over 3.5 metric tons\",\n",
    " \"Right-of-way at intersection\", \"Priority road\", \"Yield\", \"Stop\", \"No vehicles\",\n",
    " \"Vehicles over 3.5 tons prohibited\", \"No entry\", \"General caution\", \"Dangerous curve left\",\n",
    " \"Dangerous curve right\", \"Double curve\", \"Bumpy road\", \"Slippery road\", \"Road narrows on the right\",\n",
    " \"Road work\", \"Traffic signals\", \"Pedestrians\", \"Children crossing\", \"Bicycles crossing\",\n",
    " \"Beware of ice/snow\", \"Wild animals crossing\", \"End of all speed and passing limits\",\n",
    " \"Turn right ahead\", \"Turn left ahead\", \"Ahead only\", \"Go straight or right\",\n",
    " \"Go straight or left\", \"Keep right\", \"Keep left\", \"Roundabout mandatory\",\n",
    " \"End of no passing\", \"End no passing vehicles over 3.5 tons\",\n",
    "]\n",
    "\n",
    "def fmt_label(idx: int, names=None):\n",
    "    if names is not None and idx < len(names) and names[idx] is not None:\n",
    "        return f\"{idx} - {names[idx]}\"\n",
    "    if idx < len(ID_TO_NAME):\n",
    "        return f\"{idx} - {ID_TO_NAME[idx]}\"\n",
    "    return str(idx)\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "_mean = torch.tensor(IMAGENET_MEAN).view(1, 3, 1, 1)\n",
    "_std  = torch.tensor(IMAGENET_STD).view(1, 3, 1, 1)\n",
    "\n",
    "def denorm(x):\n",
    "    # x: normalized tensor Bx3xHxW -> returns in [roughly 0..1]\n",
    "    return x * _std.to(x.device) + _mean.to(x.device)\n",
    "\n",
    "def renorm(x01):\n",
    "    # x01: Bx3xHxW in [0..1] -> returns normalized tensor\n",
    "    return (x01 - _mean.to(x01.device)) / _std.to(x01.device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_patch_effect_miscls(model, loader, device, patch, P=64, max_images=12):\n",
    "    \"\"\"\n",
    "    Coleta casos em que:\n",
    "    - sem patch: acerta\n",
    "    - com patch: erra\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    cases = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits_clean = model(x)\n",
    "        pred_clean = logits_clean.argmax(dim=1)\n",
    "\n",
    "        x_patched = apply_noise_patch_batch(x_norm=x, patch_size=P, patch=patch, random_loc=True)\n",
    "        logits_patch = model(x_patched)\n",
    "        probs_patch = torch.softmax(logits_patch, dim=1)\n",
    "        pred_patch = probs_patch.argmax(dim=1)\n",
    "        conf_patch = probs_patch.max(dim=1).values\n",
    "\n",
    "        mask = (pred_clean == y) & (pred_patch != y)\n",
    "        if mask.any():\n",
    "            x_clean_cpu  = x[mask].detach().cpu()\n",
    "            x_patch_cpu  = x_patched[mask].detach().cpu()\n",
    "            y_cpu        = y[mask].detach().cpu()\n",
    "            pred_p_cpu   = pred_patch[mask].detach().cpu()\n",
    "            conf_p_cpu   = conf_patch[mask].detach().cpu()\n",
    "\n",
    "            for i in range(x_clean_cpu.size(0)):\n",
    "                cases.append((\n",
    "                    x_clean_cpu[i], x_patch_cpu[i],\n",
    "                    int(y_cpu[i]), int(pred_p_cpu[i]), float(conf_p_cpu[i])\n",
    "                ))\n",
    "                if len(cases) >= max_images:\n",
    "                    return cases\n",
    "\n",
    "    return cases\n",
    "\n",
    "\n",
    "def show_patch_comparison(cases, class_names=None):\n",
    "    if len(cases) == 0:\n",
    "        print(\"No cases where the patch worsens the situation (correct → incorrect) were found\")\n",
    "        return\n",
    "\n",
    "    rows = len(cases)\n",
    "    plt.figure(figsize=(10, 4*rows))\n",
    "\n",
    "    for i, (x_clean_norm, x_patch_norm, y_true, y_pred_patch, conf_patch) in enumerate(cases):\n",
    "        # clean\n",
    "        clean01 = denorm(x_clean_norm.unsqueeze(0)).clamp(0,1)[0]\n",
    "        clean_img = clean01.permute(1,2,0).numpy()\n",
    "\n",
    "        # patched\n",
    "        patch01 = denorm(x_patch_norm.unsqueeze(0)).clamp(0,1)[0]\n",
    "        patch_img = patch01.permute(1,2,0).numpy()\n",
    "\n",
    "        true_name = fmt_label(y_true, class_names)\n",
    "        pred_name = fmt_label(y_pred_patch, class_names)\n",
    "\n",
    "        ax1 = plt.subplot(rows, 2, 2*i + 1)\n",
    "        ax1.imshow(clean_img)\n",
    "        ax1.set_title(f\"CLEAN (true: {true_name})\")\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        ax2 = plt.subplot(rows, 2, 2*i + 2)\n",
    "        ax2.imshow(patch_img)\n",
    "        ax2.set_title(f\"PATCHED (pred: {pred_name}, conf={conf_patch:.2f})\")\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class_names = getattr(test_loader.dataset, \"classes\", None)\n",
    "cases = collect_patch_effect_miscls(model, test_loader, device, patch, P=64, max_images=10)\n",
    "show_patch_comparison(cases, class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89503f59-b88d-46ac-bc6b-cebfa718f344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_confusion_matrix(model, loader, device, num_classes: int,\n",
    "                             apply_patch: bool = False, patch=None, P: int = 32):\n",
    "    model.eval()\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.int64)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        if apply_patch:\n",
    "            assert patch is not None\n",
    "            x = apply_noise_patch_batch(x_norm=x, patch_size=P, patch=patch, random_loc=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred = logits.argmax(dim=1)\n",
    "\n",
    "        idx = y * num_classes + pred\n",
    "        cm += torch.bincount(idx, minlength=num_classes * num_classes).view(num_classes, num_classes).cpu()\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm: torch.Tensor, class_names=None, normalize: bool = True,\n",
    "                          title: str = \"Confusion Matrix\", figsize=(12, 10),\n",
    "                          show_every: int = 1):\n",
    "    cm = cm.clone().float()\n",
    "\n",
    "    if normalize:\n",
    "        row_sums = cm.sum(dim=1, keepdim=True).clamp(min=1.0)\n",
    "        cm = cm / row_sums\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm.numpy(), interpolation=\"nearest\")  # sem seaborn\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    n = cm.shape[0]\n",
    "    ticks = list(range(0, n, show_every))\n",
    "    plt.xticks(ticks, ticks, rotation=90)\n",
    "    plt.yticks(ticks, ticks)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def top_confusions(cm: torch.Tensor, k: int = 15, class_names=None):\n",
    "    cm = cm.clone()\n",
    "    n = cm.shape[0]\n",
    "    cm.fill_diagonal_(0)  # zera acertos\n",
    "    flat = cm.view(-1)\n",
    "\n",
    "    vals, idxs = torch.topk(flat, k=min(k, flat.numel()))\n",
    "    results = []\n",
    "\n",
    "    for v, idx in zip(vals.tolist(), idxs.tolist()):\n",
    "        if v == 0:\n",
    "            continue\n",
    "        true = idx // n\n",
    "        pred = idx % n\n",
    "\n",
    "        def fmt(i):\n",
    "            if class_names and i < len(class_names):\n",
    "                return f\"{i} - {class_names[i]}\"\n",
    "            if ID_TO_NAME and i < len(ID_TO_NAME):\n",
    "                return f\"{i} - {ID_TO_NAME[i]}\"\n",
    "            return str(i)\n",
    "\n",
    "        results.append((v, fmt(true), fmt(pred)))\n",
    "\n",
    "    print(\"\\nTop confusões (erros mais frequentes):\")\n",
    "    for v, t, p in results:\n",
    "        print(f\"{v:6d}  true: {t:<40}  pred: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3bf85-25b2-4caf-88f3-f0419cd34c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 43\n",
    "class_names = getattr(test_loader.dataset, \"classes\", None)\n",
    "\n",
    "cm_clean = compute_confusion_matrix(model, test_loader, device, num_classes, apply_patch=False)\n",
    "plot_confusion_matrix(cm_clean, class_names=class_names, normalize=True,\n",
    "                      title=\"GTSRB - Confusion Matrix (CLEAN, normalized)\", show_every=1)\n",
    "top_confusions(cm_clean, k=15, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ef97e-bfcf-4f4c-8588-6022acbac0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_patch = compute_confusion_matrix(model, test_loader, device, num_classes,\n",
    "                                    apply_patch=True, patch=patch, P=64)\n",
    "plot_confusion_matrix(cm_patch, class_names=class_names, normalize=True,\n",
    "                      title=\"GTSRB - Confusion Matrix (PATCHED, normalized)\", show_every=1)\n",
    "top_confusions(cm_patch, k=15, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7311d99-202e-4046-9745-172c4238a81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_diff = (cm_patch - cm_clean).clamp(min=0)\n",
    "plot_confusion_matrix(cm_diff, normalize=False,\n",
    "                      title=\"GTSRB - Confusion Matrix DIFF (PATCHED - CLEAN)\", show_every=1)\n",
    "top_confusions(cm_diff, k=15, class_names=class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
